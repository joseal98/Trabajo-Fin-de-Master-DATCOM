{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajo Fin de Máster <br/> Diseño de una arquitectura multimodal para descripción textual de pares imagen-audio\n",
        "\n",
        "## Script 2. Entrenamiento de un clasificador de audio usando PyTorch\n",
        "\n",
        "En este notebook, aprendemos a clasificar los audios que hemos generado, con la ayuda de PyTorch. Para ello, usamos lo compartido en el artículo de [TowardsDataScience](https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5)."
      ],
      "metadata": {
        "id": "mROJteeudBtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1. Cambio de directorio e importaciones necesarias"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('..')\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721672473422
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Configuración e inicialización de wandb"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Login to your wandb account so you can log all your metrics\n",
        "import wandb"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721672478343
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 1b8abaacf33b7b5812267384768c22a1eef3c11e"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/azureuser/.netrc\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = './../Final_Database'\n",
        "num_epochs = 30\n",
        "BATCH_SIZE = 16\n",
        "lr = 1e-3\n",
        "output_dim = 20\n",
        "\n",
        "model_parameters_file = f\"./modelos/audio/AUDIO_{output_dim}pers_lr{f'{lr:.0e}'}_bs{BATCH_SIZE}_{num_epochs}ep.pt\"\n",
        "model_parameters_file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'./modelos/audio/AUDIO_20pers_lr1e-03_bs16_30ep.pt'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721672483352
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Initialize a new run\n",
        "run_name = model_parameters_file.split(\"/\")[-1].replace('.pt', '')\n",
        "wandb.init(entity=\"josealbertoap\", project='TFM', name = run_name, tags=[\"audio\"])\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config          # Initialize config\n",
        "config.batch_size = BATCH_SIZE          # input batch size for training (default: 64)\n",
        "config.test_batch_size = BATCH_SIZE    # input batch size for testing (default: 1000)\n",
        "config.epochs = num_epochs             # number of epochs to train (default: 10)\n",
        "config.lr = lr              # learning rate (default: 0.01)\n",
        "config.momentum = 0          # SGD momentum (default: 0.5)\n",
        "config.no_cuda = True         # disables CUDA training\n",
        "config.seed = 0               # random seed (default: 42)\n",
        "config.log_interval = 1     # how many batches to wait before logging training status\n",
        "config.num_classes = output_dim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjosealbertoap\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.5"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts/wandb/run-20240722_182125-r6kkn3qw</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/josealbertoap/TFM/runs/r6kkn3qw' target=\"_blank\">AUDIO_20pers_lr1e-03_bs16_30ep</a></strong> to <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">https://wandb.ai/josealbertoap/TFM</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/josealbertoap/TFM/runs/r6kkn3qw' target=\"_blank\">https://wandb.ai/josealbertoap/TFM/runs/r6kkn3qw</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721672497195
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Lectura de los audios generados\n",
        "Leemos los audios de nuestra base de datos y los guardamos en un dataset compuesto por sus respectivos espectrogramas.\n",
        "\n",
        "Posteriormente, usamos los datasets de entrenamiento y validación para generar los respectivos DataLoaders que emplearemos en el entrenamiento de la red."
      ],
      "metadata": {
        "id": "RV4cs85P22Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(config.seed)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "J5zavNLM49sr",
        "gather": {
          "logged": 1721672512683
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import random_split\n",
        "from tfm_lib.datasets import SoundDS\n",
        "\n",
        "database_df = pd.read_csv(f\"{folder_path}/audio/audioDB_train.csv\")\n",
        "myds = SoundDS(database_df, './', output_dim)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "M1nT__codBtj",
        "gather": {
          "logged": 1721672521391
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3. Entrenamiento de la red"
      ],
      "metadata": {
        "id": "LpwecWiv3dQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from tfm_lib.EarlyStopping import EarlyStopping\n",
        "\n",
        "# ----------------------------\n",
        "# Training Loop\n",
        "# ----------------------------\n",
        "def training(model, train_dl, val_dl, num_epochs):\n",
        "  # Loss Function, Optimizer and Scheduler\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
        "\n",
        "  # Inicializar EarlyStopping\n",
        "  early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path=model_parameters_file)\n",
        "\n",
        "  train_loss = {}\n",
        "  test_loss = {}\n",
        "  train_acc = {}\n",
        "  test_acc = {}\n",
        "\n",
        "  # Repeat for each epoch\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "\n",
        "    train_steps = tqdm(train_dl, unit=\"batch\")\n",
        "\n",
        "    # Repeat for each batch in the training set\n",
        "    for i, data in enumerate(train_steps):\n",
        "\n",
        "        train_steps.set_description(f\"Epoch [{epoch+1}/{num_epochs}]. Training\")\n",
        "\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        # Keep stats for Loss and Accuracy\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        train_steps.set_postfix(mean_loss=running_loss/total_prediction, mean_accuracy = correct_prediction / total_prediction)\n",
        "\n",
        "    # Print stats at the end of the epoch\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
        "    print(f'Training. Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "\n",
        "    train_loss[epoch+1] = avg_loss\n",
        "    train_acc[epoch+1] = acc\n",
        "\n",
        "    # Validación del modelo\n",
        "    model.eval()\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    # Disable gradient updates\n",
        "    with torch.no_grad():\n",
        "\n",
        "      predictions = []\n",
        "      label_list = []\n",
        "      for data in val_dl:\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Get predictions\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        predictions.extend(prediction)\n",
        "        label_list.extend(data[1])\n",
        "\n",
        "    acc = correct_prediction/total_prediction\n",
        "    val_loss = running_loss / len(val_dl)\n",
        "\n",
        "    print(f'Validation. Loss: {val_loss:.6f}, Accuracy: {acc:.6f}')\n",
        "\n",
        "    test_loss[epoch+1] = val_loss\n",
        "    test_acc[epoch+1] = acc\n",
        "\n",
        "    # Llamar a early_stopping con la pérdida de validación actual y el modelo\n",
        "    early_stopping(val_loss, model)\n",
        "    print('')\n",
        "\n",
        "    # Si se alcanza el criterio de early stopping, romper el bucle\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "      \n",
        "    # Cambiar learning rate si hace falta\n",
        "    scheduler.step(test_loss[epoch+1])\n",
        "\n",
        "    wandb.log({\n",
        "      'Epoch': epoch+1,\n",
        "      'Training Loss': train_loss[epoch+1],\n",
        "      'Training Accuracy': train_acc[epoch+1],\n",
        "      'Evaluation Loss': test_loss[epoch+1],\n",
        "      'Evaluation Accuracy': test_acc[epoch+1],\n",
        "      })\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  return {'train_acc': train_acc, 'train_loss': train_loss, 'val_acc': test_acc, 'val_loss': test_loss}"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "zNWZH4zidBtm",
        "gather": {
          "logged": 1721672521611
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and put it on the GPU if available\n",
        "from tfm_lib.modelos import AudioClassifier\n",
        "model = AudioClassifier(output_dim)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "# Run the training process\n",
        "training_results = training(model, train_dl, val_dl, num_epochs)\n",
        "\n",
        "print(training_results)\n",
        "wandb.save(model_parameters_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\nEpoch [1/30]. Training: 100%|██████████| 35/35 [02:09<00:00,  3.69s/batch, mean_accuracy=0.185, mean_loss=0.179] \nEpoch [2/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.39s/batch, mean_accuracy=0.386, mean_loss=0.155]\nEpoch [3/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.39s/batch, mean_accuracy=0.554, mean_loss=0.134]\nEpoch [4/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.37s/batch, mean_accuracy=0.661, mean_loss=0.115]\nEpoch [5/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.39s/batch, mean_accuracy=0.763, mean_loss=0.0976]\nEpoch [6/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.37s/batch, mean_accuracy=0.793, mean_loss=0.0832]\nEpoch [7/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.39s/batch, mean_accuracy=0.819, mean_loss=0.0689]\nEpoch [8/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.38s/batch, mean_accuracy=0.882, mean_loss=0.0572]\nEpoch [9/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.37s/batch, mean_accuracy=0.92, mean_loss=0.0473] \nEpoch [10/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.35s/batch, mean_accuracy=0.924, mean_loss=0.0407]\nEpoch [11/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.38s/batch, mean_accuracy=0.958, mean_loss=0.0325]\nEpoch [12/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.35s/batch, mean_accuracy=0.984, mean_loss=0.0274]\nEpoch [13/30]. Training: 100%|██████████| 35/35 [01:59<00:00,  3.41s/batch, mean_accuracy=0.966, mean_loss=0.0225]\nEpoch [14/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.36s/batch, mean_accuracy=0.976, mean_loss=0.0193]\nEpoch [15/30]. Training: 100%|██████████| 35/35 [01:58<00:00,  3.38s/batch, mean_accuracy=0.982, mean_loss=0.0162]\nEpoch [16/30]. Training: 100%|██████████| 35/35 [01:56<00:00,  3.33s/batch, mean_accuracy=0.989, mean_loss=0.0141]\nEpoch [17/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.37s/batch, mean_accuracy=0.993, mean_loss=0.0125]\nEpoch [18/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.35s/batch, mean_accuracy=0.993, mean_loss=0.0114]\nEpoch [19/30]. Training: 100%|██████████| 35/35 [01:57<00:00,  3.36s/batch, mean_accuracy=0.993, mean_loss=0.0091] \nEpoch [20/30]. Training:  69%|██████▊   | 24/35 [01:21<00:37,  3.43s/batch, mean_accuracy=0.982, mean_loss=0.00982]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch [1/30]:\nTraining. Loss: 2.82, Accuracy: 0.18\nValidation. Loss: 2.610347, Accuracy: 0.304348\nValidation loss decreased (inf --> 2.610347).  Saving model ...\n\nEpoch [2/30]:\nTraining. Loss: 2.44, Accuracy: 0.39\nValidation. Loss: 2.288727, Accuracy: 0.369565\nValidation loss decreased (2.610347 --> 2.288727).  Saving model ...\n\nEpoch [3/30]:\nTraining. Loss: 2.11, Accuracy: 0.55\nValidation. Loss: 2.012730, Accuracy: 0.471014\nValidation loss decreased (2.288727 --> 2.012730).  Saving model ...\n\nEpoch [4/30]:\nTraining. Loss: 1.82, Accuracy: 0.66\nValidation. Loss: 1.922779, Accuracy: 0.485507\nValidation loss decreased (2.012730 --> 1.922779).  Saving model ...\n\nEpoch [5/30]:\nTraining. Loss: 1.54, Accuracy: 0.76\nValidation. Loss: 1.519020, Accuracy: 0.623188\nValidation loss decreased (1.922779 --> 1.519020).  Saving model ...\n\nEpoch [6/30]:\nTraining. Loss: 1.31, Accuracy: 0.79\nValidation. Loss: 1.135658, Accuracy: 0.782609\nValidation loss decreased (1.519020 --> 1.135658).  Saving model ...\n\nEpoch [7/30]:\nTraining. Loss: 1.09, Accuracy: 0.82\nValidation. Loss: 1.028429, Accuracy: 0.782609\nValidation loss decreased (1.135658 --> 1.028429).  Saving model ...\n\nEpoch [8/30]:\nTraining. Loss: 0.90, Accuracy: 0.88\nValidation. Loss: 0.855622, Accuracy: 0.833333\nValidation loss decreased (1.028429 --> 0.855622).  Saving model ...\n\nEpoch [9/30]:\nTraining. Loss: 0.75, Accuracy: 0.92\nValidation. Loss: 0.671725, Accuracy: 0.905797\nValidation loss decreased (0.855622 --> 0.671725).  Saving model ...\n\nEpoch [10/30]:\nTraining. Loss: 0.64, Accuracy: 0.92\nValidation. Loss: 0.598266, Accuracy: 0.898551\nValidation loss decreased (0.671725 --> 0.598266).  Saving model ...\n\nEpoch [11/30]:\nTraining. Loss: 0.51, Accuracy: 0.96\nValidation. Loss: 0.498429, Accuracy: 0.898551\nValidation loss decreased (0.598266 --> 0.498429).  Saving model ...\n\nEpoch [12/30]:\nTraining. Loss: 0.43, Accuracy: 0.98\nValidation. Loss: 0.438402, Accuracy: 0.920290\nValidation loss decreased (0.498429 --> 0.438402).  Saving model ...\n\nEpoch [13/30]:\nTraining. Loss: 0.35, Accuracy: 0.97\nValidation. Loss: 0.464016, Accuracy: 0.876812\nEarlyStopping counter: 1 out of 5\n\nEpoch [14/30]:\nTraining. Loss: 0.30, Accuracy: 0.98\nValidation. Loss: 0.384450, Accuracy: 0.905797\nValidation loss decreased (0.438402 --> 0.384450).  Saving model ...\n\nEpoch [15/30]:\nTraining. Loss: 0.26, Accuracy: 0.98\nValidation. Loss: 0.343742, Accuracy: 0.920290\nValidation loss decreased (0.384450 --> 0.343742).  Saving model ...\n\nEpoch [16/30]:\nTraining. Loss: 0.22, Accuracy: 0.99\nValidation. Loss: 0.301142, Accuracy: 0.913043\nValidation loss decreased (0.343742 --> 0.301142).  Saving model ...\n\nEpoch [17/30]:\nTraining. Loss: 0.20, Accuracy: 0.99\nValidation. Loss: 0.246941, Accuracy: 0.934783\nValidation loss decreased (0.301142 --> 0.246941).  Saving model ...\n\nEpoch [18/30]:\nTraining. Loss: 0.18, Accuracy: 0.99\nValidation. Loss: 0.250952, Accuracy: 0.934783\nEarlyStopping counter: 1 out of 5\n\nEpoch [19/30]:\nTraining. Loss: 0.14, Accuracy: 0.99\nValidation. Loss: 0.172834, Accuracy: 0.978261\nValidation loss decreased (0.246941 --> 0.172834).  Saving model ...\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKfiIW1r4dZT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728659625,
          "user_tz": -120,
          "elapsed": 113922,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "b69c3238-08a6-4acc-be88-c24ce03feb87",
        "gather": {
          "logged": 1721670979780
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 4. Resultados con los datos de test"
      ],
      "metadata": {
        "id": "bTM7EaVl3iDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SoundDS(pd.read_csv(f\"{folder_path}/audio/audioDB_test.csv\"), './', output_dim)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=1048, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721670979959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Inference\n",
        "# ----------------------------\n",
        "def inference (model, test_dataset):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "\n",
        "    predictions = []\n",
        "    label_list = []\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalize the inputs\n",
        "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "      inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "\n",
        "      predictions.extend(prediction)\n",
        "      label_list.extend(data[1])\n",
        "\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
        "\n",
        "  return predictions, label_list\n",
        "\n",
        "# Run inference on trained model with the validation set\n",
        "model.load_state_dict(torch.load(model_parameters_file, map_location=torch.device('cpu')))\n",
        "result = inference(model, test_dl)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "fzt1bAnBdBtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728672091,
          "user_tz": -120,
          "elapsed": 958,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "c6b92cab-da18-460c-eeb7-b4156b87340e",
        "gather": {
          "logged": 1721670996384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score, confusion_matrix\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import plotly\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    df_cm = pd.DataFrame((cf_matrix / np.sum(cf_matrix, axis=1)[:, None]).round(3),\n",
        "                         index=myds.labelencoder().classes_,\n",
        "                         columns=myds.labelencoder().classes_)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))  \n",
        "    sn.set(font_scale=1.2)  \n",
        "    heatmap = sn.heatmap(df_cm, annot=True, cbar=False, cmap='Purples', fmt='g', xticklabels=False)\n",
        "\n",
        "    # Ajusta la rotación y alineación de los ticks de los ejes\n",
        "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
        "\n",
        "    plt.tight_layout()  # Asegura que todo se ajuste bien en la figura\n",
        "    plt.savefig(model_parameters_file.replace('/modelos/', '/results/').replace('.pt', '.png'))\n",
        "\n",
        "    return plt.gcf()\n",
        "\n",
        "def get_metrics(result):\n",
        "    accuracy = accuracy_score(result[1], result[0])\n",
        "    precision = precision_score(result[1], result[0], average='macro')\n",
        "    recall = recall_score(result[1], result[0], average='macro')\n",
        "    f1 = f1_score(result[1], result[0], average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        'Test accuracy': accuracy,\n",
        "        'Test precision': precision,\n",
        "        'Test recall': recall,\n",
        "        'F1-score': f1\n",
        "    }\n",
        "\n",
        "    print(metrics)\n",
        "\n",
        "    metrics['Confusion Matrix'] = wandb.Image(plot_confusion_matrix(result[1],result[0]))\n",
        "    metrics['Test metrics'] = wandb.Table(columns=[\"Metric name\", \"Value\"], \n",
        "                                          data=[[\"Test accuracy\", accuracy], [\"Test precision\", precision],\n",
        "                                                [\"Test recall\", recall], [\"Test F1-Score\", f1]])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "metrics = get_metrics(result)\n",
        "wandb.log(metrics)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721671000362
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721671010682
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}