{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajo Fin de Máster <br/> Diseño de una arquitectura multimodal para descripción textual de pares imagen-audio\n",
        "\n",
        "## Script 3. Obtención de imágenes a partir de la base de datos\n",
        "\n",
        "En este notebook, tomamos los vídeos que forman parte de la base de datos y extraemos los fotogramas que los componen. Para ello, hacemos uso de la biblioteca OpenCV."
      ],
      "metadata": {
        "id": "f9920219"
      },
      "id": "f9920219"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1. Importación de paquetes"
      ],
      "metadata": {
        "id": "60418384"
      },
      "id": "60418384"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "13acc14d",
        "gather": {
          "logged": 1721412897020
        }
      },
      "id": "13acc14d"
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"..\")\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721412897260
        }
      },
      "id": "be6c36bd-bc21-4273-ab77-92d7d7084063"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Extracción de imágenes\n",
        "Dentro de la carpeta correspondiente a cada participante, tenemos dos archivos: 'video_sq.mp4' y 'audio.ogg'. Tomamos el primero para convertirlo en imágenes con la ayuda de `cv2`.\n",
        "\n",
        "Lo que hacemos es tomar el vídeo (de imagen cuadrada) y guardar cada uno de los frames como una imagen independiente de las demás. Con ello, acabamos teniendo una cantidad de imágenes del orden de 300-600 por persona."
      ],
      "metadata": {
        "id": "fae74881"
      },
      "id": "fae74881"
    },
    {
      "cell_type": "code",
      "source": [
        "def ImageExtraction(db_path, new_db_path, output_dim=None):\n",
        "\n",
        "    participants = os.listdir(db_path)\n",
        "\n",
        "    rel_paths_train = []\n",
        "    classID_train = []\n",
        "    rel_paths_test = []\n",
        "    classID_test = []\n",
        "    for person in participants:\n",
        "\n",
        "        if '.' in person:\n",
        "            continue\n",
        "\n",
        "        video = cv2.VideoCapture(f\"{db_path}/{person}/video_sq.mp4\")\n",
        "        folder_path = f\"{new_db_path}/image/{person}\"\n",
        "\n",
        "        number_of_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frames_skip_train = round(number_of_frames/100)\n",
        "        frames_skip_test = round(number_of_frames/100) * 3 + 1\n",
        "\n",
        "        try:\n",
        "            # Creamos la carpeta donde guardaremos las imágenes, en caso de que no exista\n",
        "            if os.path.exists(folder_path):\n",
        "                shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "        except OSError:\n",
        "            print ('Error: Creating directory of data')\n",
        "\n",
        "        # Iniciamos la cuenta de fotogramas extraídos\n",
        "        currentframe = 0\n",
        "        train_frames = 0\n",
        "        test_frames = 0\n",
        "\n",
        "        while(True):\n",
        "\n",
        "            # Leemos el fotograma. El método read() devuelve una tupla con dos valores:\n",
        "            # ret. Booleano que muestra si la lectura fue exitosa (True/False)\n",
        "            # frame. Numpy array (x,y,3) que contiene la imagen leída.\n",
        "            ret, frame = video.read()\n",
        "\n",
        "            if ret:\n",
        "                # Crear imágenes mientras quede vídeo (ret=True)\n",
        "                name = folder_path + '/frame{:0>5}.jpg'.format(currentframe)\n",
        "\n",
        "                if currentframe % frames_skip_train == 0:\n",
        "                    # Escritura del fotograma extraído\n",
        "                    resized_frame = cv2.resize(frame, output_dim) if output_dim else frame\n",
        "                    cv2.imwrite(name, resized_frame)\n",
        "                    classID_train.append(person)\n",
        "                    rel_paths_train.append(name)\n",
        "                    train_frames += 1\n",
        "                elif currentframe % frames_skip_test == 0:\n",
        "                    # Escritura del fotograma extraído\n",
        "                    resized_frame = cv2.resize(frame, output_dim) if output_dim else frame\n",
        "                    cv2.imwrite(name, resized_frame)\n",
        "                    classID_test.append(person)\n",
        "                    rel_paths_test.append(name)\n",
        "                    test_frames +=1\n",
        "\n",
        "                # Guardamos las dimensiones del primer frame para imprimirlo posteriormente.\n",
        "                if currentframe == 0:\n",
        "                    dims = resized_frame.shape\n",
        "\n",
        "                # Incrementamos la cuenta de fotogramas\n",
        "                currentframe += 1\n",
        "            else:\n",
        "                # Si ya no queda vídeo, salimos del bucle.\n",
        "                break\n",
        "\n",
        "        # Imprimimos información sobre el participante empleado.\n",
        "        print(f\"{person}: ({train_frames}+{test_frames}))/{currentframe} frames of {str(dims)}.\")\n",
        "\n",
        "    return pd.DataFrame({ 'image_path': rel_paths_train, 'classID': classID_train }), \\\n",
        "           pd.DataFrame({ 'image_path': rel_paths_test, 'classID': classID_test }),\n",
        "           \n",
        "\n",
        "train_df, test_df = ImageExtraction(\"../Database\", \"../Final_Database\")\n",
        "display(train_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Alba Azorin Zafrilla: (113+22))/339 frames of (480, 480, 3).\nAlfonso Girona Palao: (98+28))/780 frames of (480, 480, 3).\nAlfonso Vidal Lopez: (106+24))/424 frames of (480, 480, 3).\nAna Azorin Puche: (106+29))/739 frames of (480, 480, 3).\nAna Puche Palao: (98+29))/1069 frames of (480, 480, 3).\nAngela Espinosa Martinez: (94+21))/373 frames of (480, 480, 3).\nClara Hidalgo Lopez: (102+27))/612 frames of (480, 480, 3).\nCristina Carpena Ortiz: (103+28))/720 frames of (480, 480, 3).\nDavid Azorin Soriano: (125+0))/125 frames of (480, 480, 3).\nDiego Molina Puche: (112+22))/335 frames of (432, 432, 3).\nEva Jimenez Mariscal: (109+22))/325 frames of (480, 480, 3).\nFrancisco Jose Maldonado Montiel: (98+24))/486 frames of (480, 480, 3).\nGenesis Reyes Arteaga: (91+21))/363 frames of (480, 480, 3).\nIrene Gutierrez Perez: (105+28))/630 frames of (480, 480, 3).\nIrene Molina Puche: (105+21))/315 frames of (480, 480, 3).\nIrene Ponte Ibanez: (109+28))/545 frames of (480, 480, 3).\nIria Alonso Alves: (107+28))/640 frames of (480, 480, 3).\nJavier Lopez Martínez: (103+24))/412 frames of (480, 480, 3).\nJonathan Gonzalez Lopez: (106+24))/423 frames of (480, 480, 3).\nJorge Salinas Puche: (92+23))/456 frames of (480, 480, 3).\nJose Alberto Azorin Puche: (101+26))/605 frames of (480, 480, 3).\nJose Azorin Verdu: (104+31))/1449 frames of (480, 480, 3).\nJose Duenas García: (112+26))/448 frames of (480, 480, 3).\nJose Manuel Nieto del Valle: (98+26))/682 frames of (480, 480, 3).\nJoseju Ubric Quesada: (110+28))/546 frames of (480, 480, 3).\nJuan Cuesta Lopez: (91+23))/455 frames of (480, 480, 3).\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acb04cb2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716287596923,
          "user_tz": -120,
          "elapsed": 59884,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "8d44bfcb-5179-442f-d3b2-7c847cd62f80",
        "gather": {
          "logged": 1721414035932
        }
      },
      "id": "acb04cb2"
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('../Final_Database/image/imagesDB_train.csv', index=False)\n",
        "test_df.to_csv('../Final_Database/image/imagesDB_test.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "82df266a"
      },
      "id": "82df266a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}