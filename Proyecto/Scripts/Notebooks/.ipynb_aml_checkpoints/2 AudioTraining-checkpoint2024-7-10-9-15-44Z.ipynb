{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajo Fin de Máster <br/> Diseño de una arquitectura multimodal para descripción textual de pares imagen-audio\n",
        "\n",
        "## Script 2. Entrenamiento de un clasificador de audio usando PyTorch\n",
        "\n",
        "En este notebook, aprendemos a clasificar los audios que hemos generado, con la ayuda de PyTorch. Para ello, usamos lo compartido en el artículo de [TowardsDataScience](https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5)."
      ],
      "metadata": {
        "id": "mROJteeudBtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1. Cambio de directorio e importaciones necesarias"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('..')\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241954032
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Configuración e inicialización de wandb"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Login to your wandb account so you can log all your metrics\n",
        "import wandb"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241955922
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 1b8abaacf33b7b5812267384768c22a1eef3c11e"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/azureuser/.netrc\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = './../Final_Database'\n",
        "num_epochs = 30\n",
        "BATCH_SIZE = 16\n",
        "lr = 1e-3\n",
        "output_dim = 40\n",
        "\n",
        "model_parameters_file = f\"./modelos/audio/AUDIO_2_{output_dim}pers_lr{f'{lr:.0e}'}_bs{BATCH_SIZE}_{num_epochs}ep.pt\"\n",
        "model_parameters_file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'./modelos/audio/AUDIO_2_40pers_lr1e-03_bs16_30ep.pt'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241959661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Initialize a new run\n",
        "run_name = model_parameters_file.split(\"/\")[-1].replace('.pt', '')\n",
        "wandb.init(entity=\"josealbertoap\", project='TFM', name = run_name, tags=[\"audio\"])\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config          # Initialize config\n",
        "config.batch_size = BATCH_SIZE          # input batch size for training (default: 64)\n",
        "config.test_batch_size = BATCH_SIZE    # input batch size for testing (default: 1000)\n",
        "config.epochs = num_epochs             # number of epochs to train (default: 10)\n",
        "config.lr = lr              # learning rate (default: 0.01)\n",
        "config.momentum = 0          # SGD momentum (default: 0.5)\n",
        "config.no_cuda = True         # disables CUDA training\n",
        "config.seed = 0               # random seed (default: 42)\n",
        "config.log_interval = 1     # how many batches to wait before logging training status\n",
        "config.num_classes = output_dim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjosealbertoap\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.5"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts/wandb/run-20240809_221921-t1x15hut</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/josealbertoap/TFM/runs/t1x15hut' target=\"_blank\">AUDIO_2_40pers_lr1e-03_bs16_30ep</a></strong> to <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">https://wandb.ai/josealbertoap/TFM</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/josealbertoap/TFM/runs/t1x15hut' target=\"_blank\">https://wandb.ai/josealbertoap/TFM/runs/t1x15hut</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241970201
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Lectura de los audios generados\n",
        "Leemos los audios de nuestra base de datos y los guardamos en un dataset compuesto por sus respectivos espectrogramas.\n",
        "\n",
        "Posteriormente, usamos los datasets de entrenamiento y validación para generar los respectivos DataLoaders que emplearemos en el entrenamiento de la red."
      ],
      "metadata": {
        "id": "RV4cs85P22Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(config.seed)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "J5zavNLM49sr",
        "gather": {
          "logged": 1723241978905
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import random_split\n",
        "from tfm_lib.datasets import SoundDS\n",
        "\n",
        "database_df = pd.read_csv(f\"{folder_path}/audio/audioDB_train.csv\")\n",
        "myds = SoundDS(database_df, './', output_dim)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1048, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "M1nT__codBtj",
        "gather": {
          "logged": 1723241981798
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3. Entrenamiento de la red"
      ],
      "metadata": {
        "id": "LpwecWiv3dQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from tfm_lib.EarlyStopping import EarlyStopping\n",
        "\n",
        "# ----------------------------\n",
        "# Training Loop\n",
        "# ----------------------------\n",
        "def training(model, train_dl, val_dl, num_epochs):\n",
        "  # Loss Function, Optimizer and Scheduler\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
        "\n",
        "  # Inicializar EarlyStopping\n",
        "  early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path=model_parameters_file)\n",
        "\n",
        "  train_loss = {}\n",
        "  test_loss = {}\n",
        "  train_acc = {}\n",
        "  test_acc = {}\n",
        "\n",
        "  # Repeat for each epoch\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "\n",
        "    train_steps = tqdm(train_dl, unit=\"batch\")\n",
        "\n",
        "    # Repeat for each batch in the training set\n",
        "    for i, data in enumerate(train_steps):\n",
        "\n",
        "        train_steps.set_description(f\"Epoch [{epoch+1}/{num_epochs}]. Training\")\n",
        "\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        # Keep stats for Loss and Accuracy\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        train_steps.set_postfix(mean_loss=running_loss/total_prediction, mean_accuracy = correct_prediction / total_prediction)\n",
        "\n",
        "    # Print stats at the end of the epoch\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
        "    print(f'Training. Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "\n",
        "    train_loss[epoch+1] = avg_loss\n",
        "    train_acc[epoch+1] = acc\n",
        "\n",
        "    # Validación del modelo\n",
        "    model.eval()\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    # Disable gradient updates\n",
        "    with torch.no_grad():\n",
        "\n",
        "      predictions = []\n",
        "      label_list = []\n",
        "      for data in val_dl:\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Get predictions\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        predictions.extend(prediction)\n",
        "        label_list.extend(data[1])\n",
        "\n",
        "    acc = correct_prediction/total_prediction\n",
        "    val_loss = running_loss / len(val_dl)\n",
        "\n",
        "    print(f'Validation. Loss: {val_loss:.6f}, Accuracy: {acc:.6f}')\n",
        "\n",
        "    test_loss[epoch+1] = val_loss\n",
        "    test_acc[epoch+1] = acc\n",
        "\n",
        "    # Llamar a early_stopping con la pérdida de validación actual y el modelo\n",
        "    early_stopping(val_loss, model)\n",
        "    print('')\n",
        "\n",
        "    # Si se alcanza el criterio de early stopping, romper el bucle\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "      \n",
        "    # Cambiar learning rate si hace falta\n",
        "    scheduler.step(test_loss[epoch+1])\n",
        "\n",
        "    wandb.log({\n",
        "      'Epoch': epoch+1,\n",
        "      'Training Loss': train_loss[epoch+1],\n",
        "      'Training Accuracy': train_acc[epoch+1],\n",
        "      'Evaluation Loss': test_loss[epoch+1],\n",
        "      'Evaluation Accuracy': test_acc[epoch+1],\n",
        "      })\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  return {'train_acc': train_acc, 'train_loss': train_loss, 'val_acc': test_acc, 'val_loss': test_loss}"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "zNWZH4zidBtm",
        "gather": {
          "logged": 1723241982154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and put it on the GPU if available\n",
        "from tfm_lib.modelos import AudioClassifier\n",
        "model = AudioClassifier(output_dim)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "# Run the training process\n",
        "training_results = training(model, train_dl, val_dl, num_epochs)\n",
        "\n",
        "print(training_results)\n",
        "wandb.save(model_parameters_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\nEpoch [1/30]. Training: 100%|██████████| 73/73 [04:44<00:00,  3.89s/batch, mean_accuracy=0.112, mean_loss=0.221] \nEpoch [2/30]. Training: 100%|██████████| 73/73 [04:23<00:00,  3.60s/batch, mean_accuracy=0.265, mean_loss=0.19] \nEpoch [3/30]. Training: 100%|██████████| 73/73 [04:21<00:00,  3.58s/batch, mean_accuracy=0.438, mean_loss=0.159]\nEpoch [4/30]. Training: 100%|██████████| 73/73 [04:19<00:00,  3.55s/batch, mean_accuracy=0.59, mean_loss=0.13]  \nEpoch [5/30]. Training: 100%|██████████| 73/73 [04:20<00:00,  3.57s/batch, mean_accuracy=0.699, mean_loss=0.103]\nEpoch [6/30]. Training: 100%|██████████| 73/73 [04:20<00:00,  3.57s/batch, mean_accuracy=0.796, mean_loss=0.0817]\nEpoch [7/30]. Training: 100%|██████████| 73/73 [04:19<00:00,  3.55s/batch, mean_accuracy=0.867, mean_loss=0.0632]\nEpoch [8/30]. Training: 100%|██████████| 73/73 [04:18<00:00,  3.54s/batch, mean_accuracy=0.879, mean_loss=0.0525]\nEpoch [9/30]. Training: 100%|██████████| 73/73 [04:18<00:00,  3.54s/batch, mean_accuracy=0.932, mean_loss=0.0403]\nEpoch [10/30]. Training: 100%|██████████| 73/73 [04:19<00:00,  3.56s/batch, mean_accuracy=0.956, mean_loss=0.033] \nEpoch [11/30]. Training: 100%|██████████| 73/73 [04:19<00:00,  3.56s/batch, mean_accuracy=0.958, mean_loss=0.0271]\nEpoch [12/30]. Training: 100%|██████████| 73/73 [04:17<00:00,  3.53s/batch, mean_accuracy=0.961, mean_loss=0.0231]\nEpoch [13/30]. Training: 100%|██████████| 73/73 [04:22<00:00,  3.59s/batch, mean_accuracy=0.985, mean_loss=0.0184]\nEpoch [14/30]. Training:   7%|▋         | 5/73 [00:22<04:11,  3.70s/batch, mean_accuracy=0.979, mean_loss=0.017] \rEpoch [14/30]. Training:   8%|▊         | 6/73 [00:22<04:09,  3.73s/batch, mean_accuracy=0.979, mean_loss=0.017]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch [1/30]:\nTraining. Loss: 3.52, Accuracy: 0.11\nValidation. Loss: 3.226991, Accuracy: 0.162069\nValidation loss decreased (inf --> 3.226991).  Saving model ...\n\nEpoch [2/30]:\nTraining. Loss: 3.03, Accuracy: 0.27\nValidation. Loss: 2.697292, Accuracy: 0.337931\nValidation loss decreased (3.226991 --> 2.697292).  Saving model ...\n\nEpoch [3/30]:\nTraining. Loss: 2.53, Accuracy: 0.44\nValidation. Loss: 2.221926, Accuracy: 0.427586\nValidation loss decreased (2.697292 --> 2.221926).  Saving model ...\n\nEpoch [4/30]:\nTraining. Loss: 2.07, Accuracy: 0.59\nValidation. Loss: 1.787513, Accuracy: 0.644828\nValidation loss decreased (2.221926 --> 1.787513).  Saving model ...\n\nEpoch [5/30]:\nTraining. Loss: 1.65, Accuracy: 0.70\nValidation. Loss: 1.405577, Accuracy: 0.758621\nValidation loss decreased (1.787513 --> 1.405577).  Saving model ...\n\nEpoch [6/30]:\nTraining. Loss: 1.30, Accuracy: 0.80\nValidation. Loss: 1.130875, Accuracy: 0.813793\nValidation loss decreased (1.405577 --> 1.130875).  Saving model ...\n\nEpoch [7/30]:\nTraining. Loss: 1.01, Accuracy: 0.87\nValidation. Loss: 0.943313, Accuracy: 0.817241\nValidation loss decreased (1.130875 --> 0.943313).  Saving model ...\n\nEpoch [8/30]:\nTraining. Loss: 0.84, Accuracy: 0.88\nValidation. Loss: 0.719265, Accuracy: 0.903448\nValidation loss decreased (0.943313 --> 0.719265).  Saving model ...\n\nEpoch [9/30]:\nTraining. Loss: 0.64, Accuracy: 0.93\nValidation. Loss: 0.535845, Accuracy: 0.968966\nValidation loss decreased (0.719265 --> 0.535845).  Saving model ...\n\nEpoch [10/30]:\nTraining. Loss: 0.53, Accuracy: 0.96\nValidation. Loss: 0.477809, Accuracy: 0.920690\nValidation loss decreased (0.535845 --> 0.477809).  Saving model ...\n\nEpoch [11/30]:\nTraining. Loss: 0.43, Accuracy: 0.96\nValidation. Loss: 0.355079, Accuracy: 0.955172\nValidation loss decreased (0.477809 --> 0.355079).  Saving model ...\n\nEpoch [12/30]:\nTraining. Loss: 0.37, Accuracy: 0.96\nValidation. Loss: 0.296778, Accuracy: 0.968966\nValidation loss decreased (0.355079 --> 0.296778).  Saving model ...\n\nEpoch [13/30]:\nTraining. Loss: 0.29, Accuracy: 0.99\nValidation. Loss: 0.273719, Accuracy: 0.958621\nValidation loss decreased (0.296778 --> 0.273719).  Saving model ...\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKfiIW1r4dZT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728659625,
          "user_tz": -120,
          "elapsed": 113922,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "b69c3238-08a6-4acc-be88-c24ce03feb87",
        "gather": {
          "logged": 1723241910829
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 4. Resultados con los datos de test"
      ],
      "metadata": {
        "id": "bTM7EaVl3iDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SoundDS(pd.read_csv(f\"{folder_path}/audio/audioDB_test.csv\"), './', output_dim)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=1048, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241911325
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Inference\n",
        "# ----------------------------\n",
        "def inference (model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "\n",
        "    predictions = []\n",
        "    label_list = []\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalize the inputs\n",
        "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "      inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "\n",
        "      predictions.extend(prediction)\n",
        "      label_list.extend(data[1])\n",
        "\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
        "\n",
        "  return predictions, label_list\n",
        "\n",
        "# Run inference on trained model with the validation set\n",
        "model.load_state_dict(torch.load(model_parameters_file, map_location=torch.device('cpu')))\n",
        "result = inference(model, test_dl)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "fzt1bAnBdBtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728672091,
          "user_tz": -120,
          "elapsed": 958,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "c6b92cab-da18-460c-eeb7-b4156b87340e",
        "gather": {
          "logged": 1723241921659
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score, confusion_matrix\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def extraer_iniciales(name):\n",
        "    name_words = name.split(' ')\n",
        "    r = re.compile(\"^[A-Z][A-z]*\")\n",
        "    valid_words = list(filter(r.match, name_words))\n",
        "    if len(valid_words) <=3:\n",
        "        name = valid_words[0]\n",
        "        valid_words.remove(valid_words[0])\n",
        "    else:\n",
        "        name = f'{valid_words[0]} {valid_words[1]}'\n",
        "        valid_words.remove(valid_words[0])\n",
        "        valid_words.remove(valid_words[1])\n",
        "    surname = re.sub('(?<=[A-Z])[A-z]+', '.', ' '.join(valid_words))\n",
        "    return f'{name} {surname}'\n",
        "\n",
        "def font_scale(num_classes):\n",
        "    if num_classes <= 10:\n",
        "        return 1.0\n",
        "    elif num_classes <= 20:\n",
        "        return 0.75\n",
        "    elif num_classes <= 30:\n",
        "        return 0.65\n",
        "    else:\n",
        "        return 0.45\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    people = list(map(extraer_iniciales, myds.labelencoder().classes_))\n",
        "\n",
        "    df_cm = pd.DataFrame((cf_matrix / np.sum(cf_matrix, axis=1)[:, None]).round(3), index=people, columns=people)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))  \n",
        "    sn.set(font_scale = font_scale(df_cm.shape[0]))  \n",
        "    heatmap = sn.heatmap(df_cm, annot=True, cbar=False, cmap='Purples', fmt='g', xticklabels=False)\n",
        "\n",
        "    # Ajusta la rotación y alineación de los ticks de los ejes\n",
        "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
        "\n",
        "    plt.tight_layout()  # Asegura que todo se ajuste bien en la figura\n",
        "    plt.savefig(model_parameters_file.replace('/modelos/', '/results/').replace('.pt', '.png'))\n",
        "\n",
        "    return plt.gcf()\n",
        "\n",
        "def get_metrics(result):\n",
        "    accuracy = accuracy_score(result[1], result[0])\n",
        "    precision = precision_score(result[1], result[0], average='macro')\n",
        "    recall = recall_score(result[1], result[0], average='macro')\n",
        "    f1 = f1_score(result[1], result[0], average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        'Test accuracy': accuracy,\n",
        "        'Test precision': precision,\n",
        "        'Test recall': recall,\n",
        "        'F1-score': f1\n",
        "    }\n",
        "\n",
        "    print(metrics)\n",
        "\n",
        "    metrics['Confusion Matrix'] = wandb.Image(plot_confusion_matrix(result[1],result[0]))\n",
        "    metrics['Test metrics'] = wandb.Table(columns=[\"Metric name\", \"Value\"], \n",
        "                                          data=[[\"Test accuracy\", accuracy], [\"Test precision\", precision],\n",
        "                                                [\"Test recall\", recall], [\"Test F1-Score\", f1]])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "metrics = get_metrics(result)\n",
        "wandb.log(metrics)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241925659
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723241935920
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}