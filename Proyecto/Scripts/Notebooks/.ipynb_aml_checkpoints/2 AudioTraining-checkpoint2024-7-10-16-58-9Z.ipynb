{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajo Fin de Máster <br/> Diseño de una arquitectura multimodal para descripción textual de pares imagen-audio\n",
        "\n",
        "## Script 2. Entrenamiento de un clasificador de audio usando PyTorch\n",
        "\n",
        "En este notebook, aprendemos a clasificar los audios que hemos generado, con la ayuda de PyTorch. Para ello, usamos lo compartido en el artículo de [TowardsDataScience](https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5)."
      ],
      "metadata": {
        "id": "mROJteeudBtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1. Cambio de directorio e importaciones necesarias"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('..')\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723306486875
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Configuración e inicialización de wandb"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Login to your wandb account so you can log all your metrics\n",
        "import wandb"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723306488651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 1b8abaacf33b7b5812267384768c22a1eef3c11e"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/azureuser/.netrc\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = './../Final_Database'\n",
        "num_epochs = 30\n",
        "BATCH_SIZE = 16\n",
        "lr = 5e-4\n",
        "output_dim = 5\n",
        "\n",
        "model_parameters_file = f\"./modelos/audio/AUDIO_2_{output_dim}pers_lr{f'{lr:.0e}'}_bs{BATCH_SIZE}_{num_epochs}ep.pt\"\n",
        "model_parameters_file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'./modelos/audio/AUDIO_2_5pers_lr5e-04_bs16_30ep.pt'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723306494101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Initialize a new run\n",
        "run_name = model_parameters_file.split(\"/\")[-1].replace('.pt', '')\n",
        "wandb.init(entity=\"josealbertoap\", project='TFM', name = run_name, tags=[\"audio\"])\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config          # Initialize config\n",
        "config.batch_size = BATCH_SIZE          # input batch size for training (default: 64)\n",
        "config.test_batch_size = BATCH_SIZE    # input batch size for testing (default: 1000)\n",
        "config.epochs = num_epochs             # number of epochs to train (default: 10)\n",
        "config.lr = lr              # learning rate (default: 0.01)\n",
        "config.momentum = 0          # SGD momentum (default: 0.5)\n",
        "config.no_cuda = True         # disables CUDA training\n",
        "config.seed = 0               # random seed (default: 42)\n",
        "config.log_interval = 1     # how many batches to wait before logging training status\n",
        "config.num_classes = output_dim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjosealbertoap\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.5"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts/wandb/run-20240810_161456-56rnqlmg</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/josealbertoap/TFM/runs/56rnqlmg' target=\"_blank\">AUDIO_2_5pers_lr5e-04_bs16_30ep</a></strong> to <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">https://wandb.ai/josealbertoap/TFM</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/josealbertoap/TFM/runs/56rnqlmg' target=\"_blank\">https://wandb.ai/josealbertoap/TFM/runs/56rnqlmg</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723306508766
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Lectura de los audios generados\n",
        "Leemos los audios de nuestra base de datos y los guardamos en un dataset compuesto por sus respectivos espectrogramas.\n",
        "\n",
        "Posteriormente, usamos los datasets de entrenamiento y validación para generar los respectivos DataLoaders que emplearemos en el entrenamiento de la red."
      ],
      "metadata": {
        "id": "RV4cs85P22Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(config.seed)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "J5zavNLM49sr",
        "gather": {
          "logged": 1723306523004
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import random_split\n",
        "from tfm_lib.datasets import SoundDS\n",
        "\n",
        "database_df = pd.read_csv(f\"{folder_path}/audio/audioDB_train.csv\")\n",
        "myds = SoundDS(database_df, './', output_dim)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1048, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "M1nT__codBtj",
        "gather": {
          "logged": 1723306532337
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3. Entrenamiento de la red"
      ],
      "metadata": {
        "id": "LpwecWiv3dQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from tfm_lib.EarlyStopping import EarlyStopping\n",
        "\n",
        "# ----------------------------\n",
        "# Training Loop\n",
        "# ----------------------------\n",
        "def training(model, train_dl, val_dl, num_epochs):\n",
        "  # Loss Function, Optimizer and Scheduler\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
        "\n",
        "  # Inicializar EarlyStopping\n",
        "  early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path=model_parameters_file)\n",
        "\n",
        "  train_loss = {}\n",
        "  test_loss = {}\n",
        "  train_acc = {}\n",
        "  test_acc = {}\n",
        "\n",
        "  # Repeat for each epoch\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "\n",
        "    train_steps = tqdm(train_dl, unit=\"batch\")\n",
        "\n",
        "    # Repeat for each batch in the training set\n",
        "    for i, data in enumerate(train_steps):\n",
        "\n",
        "        train_steps.set_description(f\"Epoch [{epoch+1}/{num_epochs}]. Training\")\n",
        "\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        # Keep stats for Loss and Accuracy\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        train_steps.set_postfix(mean_loss=running_loss/total_prediction, mean_accuracy = correct_prediction / total_prediction)\n",
        "\n",
        "    # Print stats at the end of the epoch\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
        "    print(f'Training. Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "\n",
        "    train_loss[epoch+1] = avg_loss\n",
        "    train_acc[epoch+1] = acc\n",
        "\n",
        "    # Validación del modelo\n",
        "    model.eval()\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    # Disable gradient updates\n",
        "    with torch.no_grad():\n",
        "\n",
        "      predictions = []\n",
        "      label_list = []\n",
        "      for data in val_dl:\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Get predictions\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        predictions.extend(prediction)\n",
        "        label_list.extend(data[1])\n",
        "\n",
        "    acc = correct_prediction/total_prediction\n",
        "    val_loss = running_loss / len(val_dl)\n",
        "\n",
        "    print(f'Validation. Loss: {val_loss:.6f}, Accuracy: {acc:.6f}')\n",
        "\n",
        "    test_loss[epoch+1] = val_loss\n",
        "    test_acc[epoch+1] = acc\n",
        "\n",
        "    # Llamar a early_stopping con la pérdida de validación actual y el modelo\n",
        "    early_stopping(val_loss, model)\n",
        "    print('')\n",
        "\n",
        "    # Si se alcanza el criterio de early stopping, romper el bucle\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "      \n",
        "    # Cambiar learning rate si hace falta\n",
        "    scheduler.step(test_loss[epoch+1])\n",
        "\n",
        "    wandb.log({\n",
        "      'Epoch': epoch+1,\n",
        "      'Training Loss': train_loss[epoch+1],\n",
        "      'Training Accuracy': train_acc[epoch+1],\n",
        "      'Evaluation Loss': test_loss[epoch+1],\n",
        "      'Evaluation Accuracy': test_acc[epoch+1],\n",
        "      })\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  return {'train_acc': train_acc, 'train_loss': train_loss, 'val_acc': test_acc, 'val_loss': test_loss}"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "zNWZH4zidBtm",
        "gather": {
          "logged": 1723306532621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and put it on the GPU if available\n",
        "from tfm_lib.modelos import AudioClassifier\n",
        "model = AudioClassifier(output_dim)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "# Run the training process\n",
        "training_results = training(model, train_dl, val_dl, num_epochs)\n",
        "\n",
        "print(training_results)\n",
        "wandb.save(model_parameters_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\nEpoch [1/30]. Training: 100%|██████████| 9/9 [00:29<00:00,  3.24s/batch, mean_accuracy=0.328, mean_loss=0.103] \nEpoch [2/30]. Training: 100%|██████████| 9/9 [00:26<00:00,  3.00s/batch, mean_accuracy=0.567, mean_loss=0.0948]\nEpoch [3/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.664, mean_loss=0.0865]\nEpoch [4/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.754, mean_loss=0.0808]\nEpoch [5/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.866, mean_loss=0.074] \nEpoch [6/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.843, mean_loss=0.0675]\nEpoch [7/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.933, mean_loss=0.0613]\nEpoch [8/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.948, mean_loss=0.0568]\nEpoch [9/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.02s/batch, mean_accuracy=0.978, mean_loss=0.0508]\nEpoch [10/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=0.97, mean_loss=0.0441] \nEpoch [11/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.05s/batch, mean_accuracy=0.955, mean_loss=0.0413]\nEpoch [12/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.955, mean_loss=0.0388]\nEpoch [13/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.02s/batch, mean_accuracy=0.993, mean_loss=0.034] \nEpoch [14/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.05s/batch, mean_accuracy=0.978, mean_loss=0.0316]\nEpoch [15/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.978, mean_loss=0.0311]\nEpoch [16/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.07s/batch, mean_accuracy=1, mean_loss=0.0248]\nEpoch [17/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.993, mean_loss=0.0247]\nEpoch [18/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.05s/batch, mean_accuracy=0.993, mean_loss=0.0213]\nEpoch [19/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.993, mean_loss=0.0208]\nEpoch [20/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=0.993, mean_loss=0.0159]\nEpoch [21/30]. Training: 100%|██████████| 9/9 [00:26<00:00,  3.00s/batch, mean_accuracy=1, mean_loss=0.0159]\nEpoch [22/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.05s/batch, mean_accuracy=0.993, mean_loss=0.0145]\nEpoch [23/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=0.993, mean_loss=0.0137]\nEpoch [24/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.00s/batch, mean_accuracy=1, mean_loss=0.0131] \nEpoch [25/30]. Training: 100%|██████████| 9/9 [00:26<00:00,  2.99s/batch, mean_accuracy=1, mean_loss=0.0114] \nEpoch [26/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.05s/batch, mean_accuracy=1, mean_loss=0.01]   \nEpoch [27/30]. Training: 100%|██████████| 9/9 [00:26<00:00,  2.99s/batch, mean_accuracy=1, mean_loss=0.00935]\nEpoch [28/30]. Training: 100%|██████████| 9/9 [00:26<00:00,  2.99s/batch, mean_accuracy=1, mean_loss=0.00922]\nEpoch [29/30]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.02s/batch, mean_accuracy=1, mean_loss=0.00783]\nEpoch [30/30]. Training: 100%|██████████| 9/9 [00:26<00:00,  2.99s/batch, mean_accuracy=1, mean_loss=0.00757]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch [1/30]:\nTraining. Loss: 1.53, Accuracy: 0.33\nValidation. Loss: 1.593348, Accuracy: 0.294118\nValidation loss decreased (inf --> 1.593348).  Saving model ...\n\nEpoch [2/30]:\nTraining. Loss: 1.41, Accuracy: 0.57\nValidation. Loss: 1.518556, Accuracy: 0.264706\nValidation loss decreased (1.593348 --> 1.518556).  Saving model ...\n\nEpoch [3/30]:\nTraining. Loss: 1.29, Accuracy: 0.66\nValidation. Loss: 1.413736, Accuracy: 0.382353\nValidation loss decreased (1.518556 --> 1.413736).  Saving model ...\n\nEpoch [4/30]:\nTraining. Loss: 1.20, Accuracy: 0.75\nValidation. Loss: 1.305276, Accuracy: 0.588235\nValidation loss decreased (1.413736 --> 1.305276).  Saving model ...\n\nEpoch [5/30]:\nTraining. Loss: 1.10, Accuracy: 0.87\nValidation. Loss: 1.169048, Accuracy: 0.735294\nValidation loss decreased (1.305276 --> 1.169048).  Saving model ...\n\nEpoch [6/30]:\nTraining. Loss: 1.00, Accuracy: 0.84\nValidation. Loss: 1.079552, Accuracy: 0.852941\nValidation loss decreased (1.169048 --> 1.079552).  Saving model ...\n\nEpoch [7/30]:\nTraining. Loss: 0.91, Accuracy: 0.93\nValidation. Loss: 0.988865, Accuracy: 0.852941\nValidation loss decreased (1.079552 --> 0.988865).  Saving model ...\n\nEpoch [8/30]:\nTraining. Loss: 0.85, Accuracy: 0.95\nValidation. Loss: 0.927736, Accuracy: 0.823529\nValidation loss decreased (0.988865 --> 0.927736).  Saving model ...\n\nEpoch [9/30]:\nTraining. Loss: 0.76, Accuracy: 0.98\nValidation. Loss: 0.833810, Accuracy: 0.852941\nValidation loss decreased (0.927736 --> 0.833810).  Saving model ...\n\nEpoch [10/30]:\nTraining. Loss: 0.66, Accuracy: 0.97\nValidation. Loss: 0.753155, Accuracy: 0.882353\nValidation loss decreased (0.833810 --> 0.753155).  Saving model ...\n\nEpoch [11/30]:\nTraining. Loss: 0.62, Accuracy: 0.96\nValidation. Loss: 0.678510, Accuracy: 0.941176\nValidation loss decreased (0.753155 --> 0.678510).  Saving model ...\n\nEpoch [12/30]:\nTraining. Loss: 0.58, Accuracy: 0.96\nValidation. Loss: 0.632502, Accuracy: 0.911765\nValidation loss decreased (0.678510 --> 0.632502).  Saving model ...\n\nEpoch [13/30]:\nTraining. Loss: 0.51, Accuracy: 0.99\nValidation. Loss: 0.557170, Accuracy: 0.941176\nValidation loss decreased (0.632502 --> 0.557170).  Saving model ...\n\nEpoch [14/30]:\nTraining. Loss: 0.47, Accuracy: 0.98\nValidation. Loss: 0.519643, Accuracy: 0.941176\nValidation loss decreased (0.557170 --> 0.519643).  Saving model ...\n\nEpoch [15/30]:\nTraining. Loss: 0.46, Accuracy: 0.98\nValidation. Loss: 0.526322, Accuracy: 0.941176\nEarlyStopping counter: 1 out of 5\n\nEpoch [16/30]:\nTraining. Loss: 0.37, Accuracy: 1.00\nValidation. Loss: 0.468039, Accuracy: 0.941176\nValidation loss decreased (0.519643 --> 0.468039).  Saving model ...\n\nEpoch [17/30]:\nTraining. Loss: 0.37, Accuracy: 0.99\nValidation. Loss: 0.392621, Accuracy: 0.970588\nValidation loss decreased (0.468039 --> 0.392621).  Saving model ...\n\nEpoch [18/30]:\nTraining. Loss: 0.32, Accuracy: 0.99\nValidation. Loss: 0.349759, Accuracy: 0.970588\nValidation loss decreased (0.392621 --> 0.349759).  Saving model ...\n\nEpoch [19/30]:\nTraining. Loss: 0.31, Accuracy: 0.99\nValidation. Loss: 0.311619, Accuracy: 0.970588\nValidation loss decreased (0.349759 --> 0.311619).  Saving model ...\n\nEpoch [20/30]:\nTraining. Loss: 0.24, Accuracy: 0.99\nValidation. Loss: 0.306316, Accuracy: 0.970588\nEarlyStopping counter: 1 out of 5\n\nEpoch [21/30]:\nTraining. Loss: 0.24, Accuracy: 1.00\nValidation. Loss: 0.299126, Accuracy: 0.970588\nValidation loss decreased (0.311619 --> 0.299126).  Saving model ...\n\nEpoch [22/30]:\nTraining. Loss: 0.22, Accuracy: 0.99\nValidation. Loss: 0.247271, Accuracy: 1.000000\nValidation loss decreased (0.299126 --> 0.247271).  Saving model ...\n\nEpoch [23/30]:\nTraining. Loss: 0.20, Accuracy: 0.99\nValidation. Loss: 0.224940, Accuracy: 1.000000\nValidation loss decreased (0.247271 --> 0.224940).  Saving model ...\n\nEpoch [24/30]:\nTraining. Loss: 0.20, Accuracy: 1.00\nValidation. Loss: 0.236253, Accuracy: 0.970588\nEarlyStopping counter: 1 out of 5\n\nEpoch [25/30]:\nTraining. Loss: 0.17, Accuracy: 1.00\nValidation. Loss: 0.216641, Accuracy: 0.970588\nEarlyStopping counter: 2 out of 5\n\nEpoch [26/30]:\nTraining. Loss: 0.15, Accuracy: 1.00\nValidation. Loss: 0.183437, Accuracy: 1.000000\nValidation loss decreased (0.224940 --> 0.183437).  Saving model ...\n\nEpoch [27/30]:\nTraining. Loss: 0.14, Accuracy: 1.00\nValidation. Loss: 0.162345, Accuracy: 1.000000\nValidation loss decreased (0.183437 --> 0.162345).  Saving model ...\n\nEpoch [28/30]:\nTraining. Loss: 0.14, Accuracy: 1.00\nValidation. Loss: 0.156231, Accuracy: 1.000000\nEarlyStopping counter: 1 out of 5\n\nEpoch [29/30]:\nTraining. Loss: 0.12, Accuracy: 1.00\nValidation. Loss: 0.132494, Accuracy: 1.000000\nValidation loss decreased (0.162345 --> 0.132494).  Saving model ...\n\nEpoch [30/30]:\nTraining. Loss: 0.11, Accuracy: 1.00\nValidation. Loss: 0.123986, Accuracy: 1.000000\nEarlyStopping counter: 1 out of 5\n\nFinished Training\n{'train_acc': {1: 0.3283582089552239, 2: 0.5671641791044776, 3: 0.664179104477612, 4: 0.753731343283582, 5: 0.8656716417910447, 6: 0.8432835820895522, 7: 0.9328358208955224, 8: 0.9477611940298507, 9: 0.9776119402985075, 10: 0.9701492537313433, 11: 0.9552238805970149, 12: 0.9552238805970149, 13: 0.9925373134328358, 14: 0.9776119402985075, 15: 0.9776119402985075, 16: 1.0, 17: 0.9925373134328358, 18: 0.9925373134328358, 19: 0.9925373134328358, 20: 0.9925373134328358, 21: 1.0, 22: 0.9925373134328358, 23: 0.9925373134328358, 24: 1.0, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0}, 'train_loss': {1: 1.5340230332480536, 2: 1.4120184580485027, 3: 1.2880131933424208, 4: 1.2037243710623846, 5: 1.1020433637830946, 6: 1.0049203832944233, 7: 0.9130619168281555, 8: 0.8462252285745409, 9: 0.756029400560591, 10: 0.6567723684840732, 11: 0.6155493789248996, 12: 0.577376706732644, 13: 0.5056854552692838, 14: 0.4706715676519606, 15: 0.4625862240791321, 16: 0.3695489664872487, 17: 0.3675196104579502, 18: 0.3174014108048545, 19: 0.30917732417583466, 20: 0.23704175154368082, 21: 0.23627948098712498, 22: 0.21653084291352165, 23: 0.20427180743879741, 24: 0.19572834339406756, 25: 0.1700228527188301, 26: 0.14946751379304463, 27: 0.1392460386786196, 28: 0.13730072644021776, 29: 0.11662414338853624, 30: 0.11277658657895194}, 'val_acc': {1: 0.29411764705882354, 2: 0.2647058823529412, 3: 0.38235294117647056, 4: 0.5882352941176471, 5: 0.7352941176470589, 6: 0.8529411764705882, 7: 0.8529411764705882, 8: 0.8235294117647058, 9: 0.8529411764705882, 10: 0.8823529411764706, 11: 0.9411764705882353, 12: 0.9117647058823529, 13: 0.9411764705882353, 14: 0.9411764705882353, 15: 0.9411764705882353, 16: 0.9411764705882353, 17: 0.9705882352941176, 18: 0.9705882352941176, 19: 0.9705882352941176, 20: 0.9705882352941176, 21: 0.9705882352941176, 22: 1.0, 23: 1.0, 24: 0.9705882352941176, 25: 0.9705882352941176, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0}, 'val_loss': {1: 1.5933477878570557, 2: 1.5185561180114746, 3: 1.4137357473373413, 4: 1.305275559425354, 5: 1.1690477132797241, 6: 1.0795522928237915, 7: 0.988864541053772, 8: 0.9277356863021851, 9: 0.8338099122047424, 10: 0.7531546950340271, 11: 0.6785104274749756, 12: 0.6325021982192993, 13: 0.5571695566177368, 14: 0.5196433663368225, 15: 0.5263217687606812, 16: 0.46803924441337585, 17: 0.39262059330940247, 18: 0.34975922107696533, 19: 0.31161850690841675, 20: 0.3063161373138428, 21: 0.2991255223751068, 22: 0.24727067351341248, 23: 0.22493956983089447, 24: 0.23625339567661285, 25: 0.2166408747434616, 26: 0.18343739211559296, 27: 0.1623454988002777, 28: 0.15623147785663605, 29: 0.13249413669109344, 30: 0.12398616224527359}}\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts/wandb/run-20240810_161456-56rnqlmg/files/modelos/audio/AUDIO_2_5pers_lr5e-04_bs16_30ep.pt']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKfiIW1r4dZT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728659625,
          "user_tz": -120,
          "elapsed": 113922,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "b69c3238-08a6-4acc-be88-c24ce03feb87",
        "gather": {
          "logged": 1723307573532
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 4. Resultados con los datos de test"
      ],
      "metadata": {
        "id": "bTM7EaVl3iDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SoundDS(pd.read_csv(f\"{folder_path}/audio/audioDB_test.csv\"), './', output_dim)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=1048, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723307573858
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Inference\n",
        "# ----------------------------\n",
        "def inference (model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "\n",
        "    predictions = []\n",
        "    label_list = []\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalize the inputs\n",
        "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "      inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "\n",
        "      predictions.extend(prediction)\n",
        "      label_list.extend(data[1])\n",
        "\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
        "\n",
        "  return predictions, label_list\n",
        "\n",
        "# Run inference on trained model with the validation set\n",
        "model.load_state_dict(torch.load(model_parameters_file, map_location=torch.device('cpu')))\n",
        "result = inference(model, test_dl)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 0.99, Total items: 112\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "id": "fzt1bAnBdBtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728672091,
          "user_tz": -120,
          "elapsed": 958,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "c6b92cab-da18-460c-eeb7-b4156b87340e",
        "gather": {
          "logged": 1723307600664
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score, confusion_matrix\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def extraer_iniciales(name):\n",
        "    name_words = name.split(' ')\n",
        "    r = re.compile(\"^[A-Z][A-z]*\")\n",
        "    valid_words = list(filter(r.match, name_words))\n",
        "    if len(valid_words) <=3:\n",
        "        name = valid_words[0]\n",
        "        valid_words.remove(valid_words[0])\n",
        "    else:\n",
        "        name = f'{valid_words[0]} {valid_words[1]}'\n",
        "        valid_words.remove(valid_words[0])\n",
        "        valid_words.remove(valid_words[1])\n",
        "    surname = re.sub('(?<=[A-Z])[A-z]+', '.', ' '.join(valid_words))\n",
        "    return f'{name} {surname}'\n",
        "\n",
        "def font_scale(num_classes):\n",
        "    if num_classes <= 10:\n",
        "        return 1.0\n",
        "    elif num_classes <= 20:\n",
        "        return 0.75\n",
        "    elif num_classes <= 30:\n",
        "        return 0.65\n",
        "    else:\n",
        "        return 0.45\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    people = list(map(extraer_iniciales, myds.labelencoder().classes_))\n",
        "\n",
        "    df_cm = pd.DataFrame((cf_matrix / np.sum(cf_matrix, axis=1)[:, None]).round(3), index=people, columns=people)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))  \n",
        "    sn.set(font_scale = font_scale(df_cm.shape[0]))  \n",
        "    heatmap = sn.heatmap(df_cm, annot=True, cbar=False, cmap='Purples', fmt='g', xticklabels=False)\n",
        "\n",
        "    # Ajusta la rotación y alineación de los ticks de los ejes\n",
        "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
        "\n",
        "    plt.tight_layout()  # Asegura que todo se ajuste bien en la figura\n",
        "    plt.savefig(model_parameters_file.replace('/modelos/', '/results/').replace('.pt', '.png'))\n",
        "\n",
        "    return plt.gcf()\n",
        "\n",
        "def get_metrics(result):\n",
        "    accuracy = accuracy_score(result[1], result[0])\n",
        "    precision = precision_score(result[1], result[0], average='macro')\n",
        "    recall = recall_score(result[1], result[0], average='macro')\n",
        "    f1 = f1_score(result[1], result[0], average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        'Test accuracy': accuracy,\n",
        "        'Test precision': precision,\n",
        "        'Test recall': recall,\n",
        "        'F1-score': f1\n",
        "    }\n",
        "\n",
        "    print(metrics)\n",
        "\n",
        "    metrics['Confusion Matrix'] = wandb.Image(plot_confusion_matrix(result[1],result[0]))\n",
        "    metrics['Test metrics'] = wandb.Table(columns=[\"Metric name\", \"Value\"], \n",
        "                                          data=[[\"Test accuracy\", accuracy], [\"Test precision\", precision],\n",
        "                                                [\"Test recall\", recall], [\"Test F1-Score\", f1]])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "metrics = get_metrics(result)\n",
        "wandb.log(metrics)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'Test accuracy': 0.9910714285714286, 'Test precision': 0.992, 'Test recall': 0.9916666666666666, 'F1-score': 0.9916630481980027}\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723307604854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='0.128 MB of 0.128 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3352dbea49f40ac897bfe4eb90455fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>Evaluation Accuracy</td><td>▁▁▂▄▅▇▇▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Evaluation Loss</td><td>██▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>F1-score</td><td>▁</td></tr><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Test precision</td><td>▁</td></tr><tr><td>Test recall</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>▁▃▄▅▇▆▇▇██████████████████████</td></tr><tr><td>Training Loss</td><td>█▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>30</td></tr><tr><td>Evaluation Accuracy</td><td>1.0</td></tr><tr><td>Evaluation Loss</td><td>0.12399</td></tr><tr><td>F1-score</td><td>0.99166</td></tr><tr><td>Test accuracy</td><td>0.99107</td></tr><tr><td>Test precision</td><td>0.992</td></tr><tr><td>Test recall</td><td>0.99167</td></tr><tr><td>Training Accuracy</td><td>1.0</td></tr><tr><td>Training Loss</td><td>0.11278</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">AUDIO_2_5pers_lr5e-04_bs16_30ep</strong> at: <a href='https://wandb.ai/josealbertoap/TFM/runs/56rnqlmg' target=\"_blank\">https://wandb.ai/josealbertoap/TFM/runs/56rnqlmg</a><br/> View project at: <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">https://wandb.ai/josealbertoap/TFM</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20240810_161456-56rnqlmg/logs</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723307615483
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}