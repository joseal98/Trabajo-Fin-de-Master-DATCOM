{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Trabajo Fin de Máster <br/> Diseño de una arquitectura multimodal para descripción textual de pares imagen-audio\n",
        "\n",
        "## Script 2. Entrenamiento de un clasificador de audio usando PyTorch\n",
        "\n",
        "En este notebook, aprendemos a clasificar los audios que hemos generado, con la ayuda de PyTorch. Para ello, usamos lo compartido en el artículo de [TowardsDataScience](https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5)."
      ],
      "metadata": {
        "id": "mROJteeudBtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1. Cambio de directorio"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('..')\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723316231704
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Configuración e inicialización de wandb"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Login to your wandb account so you can log all your metrics\n",
        "import wandb"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723316233638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login #wandb_token"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/azureuser/.netrc\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = './../Final_Database'\n",
        "num_epochs = 20\n",
        "BATCH_SIZE = 16\n",
        "lr = 1e-3\n",
        "output_dim = 5\n",
        "\n",
        "model_parameters_file = f\"./modelos/audio/AUDIO_2_{output_dim}pers_lr{f'{lr:.0e}'}_bs{BATCH_SIZE}_{num_epochs}ep.pt\"\n",
        "model_parameters_file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'./modelos/audio/AUDIO_2_5pers_lr1e-03_bs16_20ep.pt'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723316239154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WandB – Initialize a new run\n",
        "run_name = model_parameters_file.split(\"/\")[-1].replace('.pt', '')\n",
        "wandb.init(entity=\"josealbertoap\", project='TFM', name = run_name, tags=[\"audio\"])\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config          # Initialize config\n",
        "config.batch_size = BATCH_SIZE          # input batch size for training (default: 64)\n",
        "config.test_batch_size = BATCH_SIZE    # input batch size for testing (default: 1000)\n",
        "config.epochs = num_epochs             # number of epochs to train (default: 10)\n",
        "config.lr = lr              # learning rate (default: 0.01)\n",
        "config.momentum = 0          # SGD momentum (default: 0.5)\n",
        "config.no_cuda = True         # disables CUDA training\n",
        "config.seed = 0               # random seed (default: 42)\n",
        "config.log_interval = 1     # how many batches to wait before logging training status\n",
        "config.num_classes = output_dim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjosealbertoap\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.5"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts/wandb/run-20240810_185721-4mw43x98</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/josealbertoap/TFM/runs/4mw43x98' target=\"_blank\">AUDIO_2_5pers_lr1e-03_bs16_20ep</a></strong> to <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">https://wandb.ai/josealbertoap/TFM</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/josealbertoap/TFM/runs/4mw43x98' target=\"_blank\">https://wandb.ai/josealbertoap/TFM/runs/4mw43x98</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723316252958
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2. Lectura de los audios generados\n",
        "Leemos los audios de nuestra base de datos y los guardamos en un dataset compuesto por sus respectivos espectrogramas.\n",
        "\n",
        "Posteriormente, usamos los datasets de entrenamiento y validación para generar los respectivos DataLoaders que emplearemos en el entrenamiento de la red."
      ],
      "metadata": {
        "id": "RV4cs85P22Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(config.seed)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "J5zavNLM49sr",
        "gather": {
          "logged": 1723316267039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import random_split\n",
        "from tfm_lib.datasets import SoundDS\n",
        "\n",
        "database_df = pd.read_csv(f\"{folder_path}/audio/audioDB_train.csv\")\n",
        "myds = SoundDS(database_df, './', output_dim)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1048, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "M1nT__codBtj",
        "gather": {
          "logged": 1723316276100
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3. Entrenamiento de la red"
      ],
      "metadata": {
        "id": "LpwecWiv3dQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from tfm_lib.EarlyStopping import EarlyStopping\n",
        "\n",
        "# ----------------------------\n",
        "# Entrenamiento\n",
        "# ----------------------------\n",
        "def training(model, train_dl, val_dl, num_epochs):\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 4)\n",
        "\n",
        "  # Inicializar EarlyStopping\n",
        "  early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path=model_parameters_file)\n",
        "\n",
        "  train_loss = {}\n",
        "  test_loss = {}\n",
        "  train_acc = {}\n",
        "  test_acc = {}\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "\n",
        "    train_steps = tqdm(train_dl, unit=\"batch\")\n",
        "\n",
        "    for i, data in enumerate(train_steps):\n",
        "\n",
        "        train_steps.set_description(f\"Epoch [{epoch+1}/{num_epochs}]. Training\")\n",
        "\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        train_steps.set_postfix(mean_loss=running_loss/total_prediction, mean_accuracy = correct_prediction / total_prediction)\n",
        "\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]:')\n",
        "    print(f'Training. Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "\n",
        "    train_loss[epoch+1] = avg_loss\n",
        "    train_acc[epoch+1] = acc\n",
        "\n",
        "    # Validación del modelo\n",
        "    model.eval()\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      predictions = []\n",
        "      label_list = []\n",
        "      for data in val_dl:\n",
        "\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        predictions.extend(prediction)\n",
        "        label_list.extend(data[1])\n",
        "\n",
        "    acc = correct_prediction/total_prediction\n",
        "    val_loss = running_loss / len(val_dl)\n",
        "\n",
        "    print(f'Validation. Loss: {val_loss:.6f}, Accuracy: {acc:.6f}')\n",
        "\n",
        "    test_loss[epoch+1] = val_loss\n",
        "    test_acc[epoch+1] = acc\n",
        "\n",
        "    # Llamar a early_stopping con la pérdida de validación actual y el modelo\n",
        "    early_stopping(val_loss, model)\n",
        "    print('')\n",
        "\n",
        "    # Si se alcanza el criterio de early stopping, romper el bucle\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "      \n",
        "    # Cambiar learning rate si hace falta\n",
        "    scheduler.step(test_loss[epoch+1])\n",
        "\n",
        "    wandb.log({\n",
        "      'Epoch': epoch+1,\n",
        "      'Training Loss': train_loss[epoch+1],\n",
        "      'Training Accuracy': train_acc[epoch+1],\n",
        "      'Evaluation Loss': test_loss[epoch+1],\n",
        "      'Evaluation Accuracy': test_acc[epoch+1],\n",
        "      })\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  return {'train_acc': train_acc, 'train_loss': train_loss, 'val_acc': test_acc, 'val_loss': test_loss}"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "zNWZH4zidBtm",
        "gather": {
          "logged": 1723316276414
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tfm_lib.modelos import AudioClassifier\n",
        "model = AudioClassifier(output_dim)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "training_results = training(model, train_dl, val_dl, num_epochs)\n",
        "\n",
        "print(training_results)\n",
        "wandb.save(model_parameters_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\nEpoch [1/20]. Training: 100%|██████████| 9/9 [00:28<00:00,  3.22s/batch, mean_accuracy=0.366, mean_loss=0.1]   \nEpoch [2/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=0.664, mean_loss=0.0853]\nEpoch [3/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=0.784, mean_loss=0.0713]\nEpoch [4/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.918, mean_loss=0.0617]\nEpoch [5/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.03s/batch, mean_accuracy=0.903, mean_loss=0.0525]\nEpoch [6/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.07s/batch, mean_accuracy=0.94, mean_loss=0.0441] \nEpoch [7/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.08s/batch, mean_accuracy=0.985, mean_loss=0.0357]\nEpoch [8/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.993, mean_loss=0.0306]\nEpoch [9/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.06s/batch, mean_accuracy=1, mean_loss=0.0242]\nEpoch [10/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=1, mean_loss=0.0176]\nEpoch [11/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.04s/batch, mean_accuracy=0.993, mean_loss=0.0159]\nEpoch [12/20]. Training: 100%|██████████| 9/9 [00:26<00:00,  3.00s/batch, mean_accuracy=0.993, mean_loss=0.0148]\nEpoch [13/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.06s/batch, mean_accuracy=0.993, mean_loss=0.0107] \nEpoch [14/20]. Training: 100%|██████████| 9/9 [00:26<00:00,  3.00s/batch, mean_accuracy=0.985, mean_loss=0.0101] \nEpoch [15/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.01s/batch, mean_accuracy=0.993, mean_loss=0.0104]\nEpoch [16/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.06s/batch, mean_accuracy=1, mean_loss=0.00725]\nEpoch [17/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.02s/batch, mean_accuracy=1, mean_loss=0.00693]\nEpoch [18/20]. Training: 100%|██████████| 9/9 [00:26<00:00,  2.99s/batch, mean_accuracy=1, mean_loss=0.0061] \nEpoch [19/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.02s/batch, mean_accuracy=0.993, mean_loss=0.00691]\nEpoch [20/20]. Training: 100%|██████████| 9/9 [00:27<00:00,  3.02s/batch, mean_accuracy=1, mean_loss=0.004]  \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch [1/20]:\nTraining. Loss: 1.49, Accuracy: 0.37\nValidation. Loss: 1.563602, Accuracy: 0.205882\nValidation loss decreased (inf --> 1.563602).  Saving model ...\n\nEpoch [2/20]:\nTraining. Loss: 1.27, Accuracy: 0.66\nValidation. Loss: 1.383107, Accuracy: 0.352941\nValidation loss decreased (1.563602 --> 1.383107).  Saving model ...\n\nEpoch [3/20]:\nTraining. Loss: 1.06, Accuracy: 0.78\nValidation. Loss: 1.153042, Accuracy: 0.647059\nValidation loss decreased (1.383107 --> 1.153042).  Saving model ...\n\nEpoch [4/20]:\nTraining. Loss: 0.92, Accuracy: 0.92\nValidation. Loss: 0.942876, Accuracy: 0.705882\nValidation loss decreased (1.153042 --> 0.942876).  Saving model ...\n\nEpoch [5/20]:\nTraining. Loss: 0.78, Accuracy: 0.90\nValidation. Loss: 0.760270, Accuracy: 0.911765\nValidation loss decreased (0.942876 --> 0.760270).  Saving model ...\n\nEpoch [6/20]:\nTraining. Loss: 0.66, Accuracy: 0.94\nValidation. Loss: 0.655717, Accuracy: 0.911765\nValidation loss decreased (0.760270 --> 0.655717).  Saving model ...\n\nEpoch [7/20]:\nTraining. Loss: 0.53, Accuracy: 0.99\nValidation. Loss: 0.555215, Accuracy: 0.911765\nValidation loss decreased (0.655717 --> 0.555215).  Saving model ...\n\nEpoch [8/20]:\nTraining. Loss: 0.46, Accuracy: 0.99\nValidation. Loss: 0.499396, Accuracy: 0.911765\nValidation loss decreased (0.555215 --> 0.499396).  Saving model ...\n\nEpoch [9/20]:\nTraining. Loss: 0.36, Accuracy: 1.00\nValidation. Loss: 0.416894, Accuracy: 0.941176\nValidation loss decreased (0.499396 --> 0.416894).  Saving model ...\n\nEpoch [10/20]:\nTraining. Loss: 0.26, Accuracy: 1.00\nValidation. Loss: 0.342620, Accuracy: 0.970588\nValidation loss decreased (0.416894 --> 0.342620).  Saving model ...\n\nEpoch [11/20]:\nTraining. Loss: 0.24, Accuracy: 0.99\nValidation. Loss: 0.285912, Accuracy: 1.000000\nValidation loss decreased (0.342620 --> 0.285912).  Saving model ...\n\nEpoch [12/20]:\nTraining. Loss: 0.22, Accuracy: 0.99\nValidation. Loss: 0.268061, Accuracy: 0.970588\nValidation loss decreased (0.285912 --> 0.268061).  Saving model ...\n\nEpoch [13/20]:\nTraining. Loss: 0.16, Accuracy: 0.99\nValidation. Loss: 0.189956, Accuracy: 1.000000\nValidation loss decreased (0.268061 --> 0.189956).  Saving model ...\n\nEpoch [14/20]:\nTraining. Loss: 0.15, Accuracy: 0.99\nValidation. Loss: 0.179743, Accuracy: 1.000000\nValidation loss decreased (0.189956 --> 0.179743).  Saving model ...\n\nEpoch [15/20]:\nTraining. Loss: 0.15, Accuracy: 0.99\nValidation. Loss: 0.195405, Accuracy: 0.970588\nEarlyStopping counter: 1 out of 5\n\nEpoch [16/20]:\nTraining. Loss: 0.11, Accuracy: 1.00\nValidation. Loss: 0.151293, Accuracy: 0.970588\nValidation loss decreased (0.179743 --> 0.151293).  Saving model ...\n\nEpoch [17/20]:\nTraining. Loss: 0.10, Accuracy: 1.00\nValidation. Loss: 0.113269, Accuracy: 1.000000\nValidation loss decreased (0.151293 --> 0.113269).  Saving model ...\n\nEpoch [18/20]:\nTraining. Loss: 0.09, Accuracy: 1.00\nValidation. Loss: 0.103441, Accuracy: 1.000000\nEarlyStopping counter: 1 out of 5\n\nEpoch [19/20]:\nTraining. Loss: 0.10, Accuracy: 0.99\nValidation. Loss: 0.082737, Accuracy: 1.000000\nValidation loss decreased (0.113269 --> 0.082737).  Saving model ...\n\nEpoch [20/20]:\nTraining. Loss: 0.06, Accuracy: 1.00\nValidation. Loss: 0.108077, Accuracy: 1.000000\nEarlyStopping counter: 1 out of 5\n\nFinished Training\n{'train_acc': {1: 0.3656716417910448, 2: 0.664179104477612, 3: 0.7835820895522388, 4: 0.917910447761194, 5: 0.9029850746268657, 6: 0.9402985074626866, 7: 0.9850746268656716, 8: 0.9925373134328358, 9: 1.0, 10: 1.0, 11: 0.9925373134328358, 12: 0.9925373134328358, 13: 0.9925373134328358, 14: 0.9850746268656716, 15: 0.9925373134328358, 16: 1.0, 17: 1.0, 18: 1.0, 19: 0.9925373134328358, 20: 1.0}, 'train_loss': {1: 1.4923155042860243, 2: 1.270527508523729, 3: 1.0609205034044054, 4: 0.9184541900952657, 5: 0.7818291650878059, 6: 0.6561678051948547, 7: 0.5310396022266812, 8: 0.45517952574623954, 9: 0.359851254357232, 10: 0.2627164059215122, 11: 0.23629497157202828, 12: 0.22068036761548784, 13: 0.15901387068960401, 14: 0.15069635212421417, 15: 0.15437530560625923, 16: 0.10791101058324178, 17: 0.1032497634490331, 18: 0.09077935210532612, 19: 0.10292768602569898, 20: 0.05956711433827877}, 'val_acc': {1: 0.20588235294117646, 2: 0.35294117647058826, 3: 0.6470588235294118, 4: 0.7058823529411765, 5: 0.9117647058823529, 6: 0.9117647058823529, 7: 0.9117647058823529, 8: 0.9117647058823529, 9: 0.9411764705882353, 10: 0.9705882352941176, 11: 1.0, 12: 0.9705882352941176, 13: 1.0, 14: 1.0, 15: 0.9705882352941176, 16: 0.9705882352941176, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0}, 'val_loss': {1: 1.5636019706726074, 2: 1.383107304573059, 3: 1.1530417203903198, 4: 0.9428759217262268, 5: 0.7602702975273132, 6: 0.6557167768478394, 7: 0.5552148222923279, 8: 0.4993962049484253, 9: 0.4168943166732788, 10: 0.3426204025745392, 11: 0.2859116494655609, 12: 0.26806095242500305, 13: 0.18995574116706848, 14: 0.17974264919757843, 15: 0.19540509581565857, 16: 0.15129289031028748, 17: 0.11326897144317627, 18: 0.10344140976667404, 19: 0.08273731172084808, 20: 0.10807695239782333}}\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/tfm-cpu/code/Users/jose.puche/Scripts/wandb/run-20240810_185721-4mw43x98/files/modelos/audio/AUDIO_2_5pers_lr1e-03_bs16_20ep.pt']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKfiIW1r4dZT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728659625,
          "user_tz": -120,
          "elapsed": 113922,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "b69c3238-08a6-4acc-be88-c24ce03feb87",
        "gather": {
          "logged": 1723316975509
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 4. Resultados con los datos de test"
      ],
      "metadata": {
        "id": "bTM7EaVl3iDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SoundDS(pd.read_csv(f\"{folder_path}/audio/audioDB_test.csv\"), './', output_dim)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=1048, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723316975753
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Inferencia\n",
        "# ----------------------------\n",
        "def inference (model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    predictions = []\n",
        "    label_list = []\n",
        "    for data in val_dl:\n",
        "\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "      inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "\n",
        "      predictions.extend(prediction)\n",
        "      label_list.extend(data[1])\n",
        "\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
        "\n",
        "  return predictions, label_list\n",
        "\n",
        "# Run inference on trained model with the validation set\n",
        "model.load_state_dict(torch.load(model_parameters_file, map_location=torch.device('cpu')))\n",
        "result = inference(model, test_dl)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 1.00, Total items: 112\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "id": "fzt1bAnBdBtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1720728672091,
          "user_tz": -120,
          "elapsed": 958,
          "user": {
            "displayName": "JOSÉ ALBERTO AZORIN PUCHE",
            "userId": "07780853208545474625"
          }
        },
        "outputId": "c6b92cab-da18-460c-eeb7-b4156b87340e",
        "gather": {
          "logged": 1723317002528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score, confusion_matrix\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def extraer_iniciales(name):\n",
        "    name_words = name.split(' ')\n",
        "    r = re.compile(\"^[A-Z][A-z]*\")\n",
        "    valid_words = list(filter(r.match, name_words))\n",
        "    if len(valid_words) <=3:\n",
        "        name = valid_words[0]\n",
        "        valid_words.remove(valid_words[0])\n",
        "    else:\n",
        "        name = f'{valid_words[0]} {valid_words[1]}'\n",
        "        valid_words.remove(valid_words[0])\n",
        "        valid_words.remove(valid_words[1])\n",
        "    surname = re.sub('(?<=[A-Z])[A-z]+', '.', ' '.join(valid_words))\n",
        "    return f'{name} {surname}'\n",
        "\n",
        "def font_scale(num_classes):\n",
        "    if num_classes <= 10:\n",
        "        return 1.0\n",
        "    elif num_classes <= 20:\n",
        "        return 0.75\n",
        "    elif num_classes <= 30:\n",
        "        return 0.65\n",
        "    else:\n",
        "        return 0.45\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    people = list(map(extraer_iniciales, myds.labelencoder().classes_))\n",
        "\n",
        "    df_cm = pd.DataFrame((cf_matrix / np.sum(cf_matrix, axis=1)[:, None]).round(3), index=people, columns=people)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))  \n",
        "    sn.set(font_scale = font_scale(df_cm.shape[0]))  \n",
        "    heatmap = sn.heatmap(df_cm, annot=True, cbar=False, cmap='Purples', fmt='g', xticklabels=False)\n",
        "\n",
        "    # Ajusta la rotación y alineación de los ticks de los ejes\n",
        "    heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
        "\n",
        "    plt.tight_layout()  # Asegura que todo se ajuste bien en la figura\n",
        "    plt.savefig(model_parameters_file.replace('/modelos/', '/results/').replace('.pt', '.png'))\n",
        "\n",
        "    return plt.gcf()\n",
        "\n",
        "def get_metrics(result):\n",
        "    accuracy = accuracy_score(result[1], result[0])\n",
        "    precision = precision_score(result[1], result[0], average='macro')\n",
        "    recall = recall_score(result[1], result[0], average='macro')\n",
        "    f1 = f1_score(result[1], result[0], average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        'Test accuracy': accuracy,\n",
        "        'Test precision': precision,\n",
        "        'Test recall': recall,\n",
        "        'F1-score': f1\n",
        "    }\n",
        "\n",
        "    print(metrics)\n",
        "\n",
        "    metrics['Confusion Matrix'] = wandb.Image(plot_confusion_matrix(result[1],result[0]))\n",
        "    metrics['Test metrics'] = wandb.Table(columns=[\"Metric name\", \"Value\"], \n",
        "                                          data=[[\"Test accuracy\", accuracy], [\"Test precision\", precision],\n",
        "                                                [\"Test recall\", recall], [\"Test F1-Score\", f1]])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "metrics = get_metrics(result)\n",
        "wandb.log(metrics)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'Test accuracy': 1.0, 'Test precision': 1.0, 'Test recall': 1.0, 'F1-score': 1.0}\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723317006646
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='0.125 MB of 0.125 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f5fc0d3465c45a0ae1beb68eaae6c50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Evaluation Accuracy</td><td>▁▂▅▅▇▇▇▇▇███████████</td></tr><tr><td>Evaluation Loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>F1-score</td><td>▁</td></tr><tr><td>Test accuracy</td><td>▁</td></tr><tr><td>Test precision</td><td>▁</td></tr><tr><td>Test recall</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>▁▄▆▇▇▇██████████████</td></tr><tr><td>Training Loss</td><td>█▇▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Evaluation Accuracy</td><td>1.0</td></tr><tr><td>Evaluation Loss</td><td>0.10808</td></tr><tr><td>F1-score</td><td>1.0</td></tr><tr><td>Test accuracy</td><td>1.0</td></tr><tr><td>Test precision</td><td>1.0</td></tr><tr><td>Test recall</td><td>1.0</td></tr><tr><td>Training Accuracy</td><td>1.0</td></tr><tr><td>Training Loss</td><td>0.05957</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">AUDIO_2_5pers_lr1e-03_bs16_20ep</strong> at: <a href='https://wandb.ai/josealbertoap/TFM/runs/4mw43x98' target=\"_blank\">https://wandb.ai/josealbertoap/TFM/runs/4mw43x98</a><br/> View project at: <a href='https://wandb.ai/josealbertoap/TFM' target=\"_blank\">https://wandb.ai/josealbertoap/TFM</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20240810_185721-4mw43x98/logs</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723317019516
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}